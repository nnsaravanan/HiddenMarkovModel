# HiddenMarkovModel
A Hidden Markov Model (HMM) is a statistical model used to represent systems with hidden states that are not directly observable. It is a probabilistic model that consists of a set of hidden states, a set of observable states, and the probabilities of transitioning between states. In an HMM, the states are the underlying "hidden" components of the model, while the observable states are the measurements or observations made from the model.

Each state in the HMM is associated with a probability distribution over the observable states, and the probabilities of transitioning from one state to another are determined by a transition matrix. HMMs are often used in sequence analysis, where the hidden states represent some underlying biological or linguistic process, and the observable states represent the actual observations or measurements made from that process.

I created 2 Algorithms that use Hidden Markov Models to calculate the highest probabilty of HMM states for each value in a given sequence. 

Viterbi's algorithm is a dynamic programming algorithm used to find the most probable sequence of hidden states in a Hidden Markov Model (HMM) that generated a given sequence of observations. The algorithm takes as input a sequence of observations and an HMM, which consists of a set of hidden states and a set of observable symbols or emissions associated with each state. The algorithm then calculates the probability of each possible path through the HMM that could have generated the given sequence of observations. The algorithm starts with the initial observation and calculates the probability of each possible state that could have generated that observation. It then proceeds to the next observation and calculates the probability of transitioning to each possible state from each possible previous state. The algorithm continues this process for all the observations in the sequence until the final observation is reached. At this point, the algorithm selects the most probable path through the HMM that generated the sequence of observations based on the maximum probability calculated during the process. The selected path represents the most probable sequence of hidden states that generated the observed sequence.


The Forward-Backwards algorithm is a method for computing the probabilities of hidden states in a Hidden Markov Model (HMM). It involves two passes over the input sequence. In the first pass (the Forward pass), the algorithm calculates the probability of the observed sequence up to a given time step and the probability of being in a particular hidden state at that time step. In the second pass (the Backward pass), the algorithm calculates the probability of the observed sequence from a given time step to the end of the sequence and the probability of being in a particular hidden state at that time step. By combining the probabilities from the Forward and Backward passes, the algorithm can compute the probability of being in a particular hidden state at a given time step, given the observed sequence. The Forward-Backwards algorithm is useful for a variety of tasks, such as computing the expected number of times a hidden state is visited in a given sequence, or estimating the parameters of an HMM from a set of observed sequences.

